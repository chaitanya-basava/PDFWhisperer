{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T01:07:29.996578Z",
     "start_time": "2024-07-30T01:07:27.760246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from server.model import LLM\n",
    "from server.pdf_parser import process_pdf\n",
    "from server.session_manager import AutoExpireDict\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ],
   "id": "fbc66f33a2d49ef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T01:07:42.023940Z",
     "start_time": "2024-07-30T01:07:40.903269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = LLM.get_llm(LLM.get_llm_by_id(2))\n",
    "retriever = process_pdf(\"/Users/chaitanyabasava/Desktop/Sai Naga Viswa Chaitanya_Basava_resume.pdf\")\n",
    "\n",
    "store = AutoExpireDict(1800, \"auto_expire_dict.pkl\", 1) # just saving 1 conversation"
   ],
   "id": "17b24082fa33e73a",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T01:07:42.190640Z",
     "start_time": "2024-07-30T01:07:42.185128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contextualize_q_system_prompt = \"\"\"\n",
    "Given a chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# takes in an input and chat_history to be invoked and returns a list of Documents\n",
    "# llm is used to generate a search prompt using the input and chat_history\n",
    "# this is then sent to the retriever to get a list of Documents\n",
    "history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)"
   ],
   "id": "368ce4fb09233198",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T01:07:42.559912Z",
     "start_time": "2024-07-30T01:07:42.554545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "human_prompt = \"\"\"\n",
    "QUESTION: {input}\n",
    "CONTEXT: {context}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant for question-answering tasks. Provide a clear, direct, and concise answer to the user's question, using the provided context. Your response should be no longer than three sentences, ensuring brevity and accuracy. If you don't know the answer, say that you don't know.\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# takes in context (list of documents)\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt, document_variable_name=\"context\")\n",
    "\n",
    "# first param can be a retriever or Runnable (another chain/llm) - should return a list of Documents\n",
    "# all the inputs passed when invoking the chain will be passed to the retriever if it's a Runnable\n",
    "# second param is a Runnable which gets the original input, the chat history, and a context with retrieved docs\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ],
   "id": "e1cc8f14e64b70be",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T01:07:42.835913Z",
     "start_time": "2024-07-30T01:07:42.830498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conversational_rag_chain = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    store.get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\",\n",
    ")"
   ],
   "id": "9adffa1aeb374da2",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T01:09:16.128880Z",
     "start_time": "2024-07-30T01:09:12.422068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = conversational_rag_chain.invoke(\n",
    "    {\"input\": \"return all my skills in programming languages\"},\n",
    "    config={\n",
    "        \"configurable\": {\"session_id\": \"abc123\"}\n",
    "    }\n",
    ")\n",
    "\n",
    "print(res[\"answer\"])"
   ],
   "id": "656d55a3e8a67b5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your programming language skills include: C/C++, Java, Python, JavaScript, TypeScript, SQL, Scala, HTML, CSS, and Golang.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b63cd2e1e8b8759f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
